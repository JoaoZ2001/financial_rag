{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "039b1d48",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "a8fa8de4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing packages\n",
                "\n",
                "# Manipulating the operating system\n",
                "import os\n",
                "\n",
                "# Function to load the pre-trained embeddings model\n",
                "from langchain_huggingface import HuggingFaceEmbeddings  \n",
                "\n",
                "# Vector database\n",
                "from langchain_chroma import Chroma  \n",
                "\n",
                "# Document loaders\n",
                "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
                "\n",
                "# Text chunk splitter\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "809d7866",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path to documents\n",
                "documents_path = \"/Users/joaovitorzimmermann/Projetos/rag_system/documents\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "2c2e6907",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definition of the directory where vector databases will be stored\n",
                "vectordb_path = \"/Users/joaovitorzimmermann/Projetos/rag_system/vector_dbs\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "d6083166",
            "metadata": {},
            "outputs": [],
            "source": [
                "emb_model_name = \"BAAI/bge-m3\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "bea96e22",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to create the vector database from processed documents\n",
                "def create_vector_db(subject):\n",
                "\n",
                "    # Message informing the start of the process\n",
                "    print(\"\\nGenerating Embeddings. Please wait...\")\n",
                "    \n",
                "    # Loading PDF files from the specified directory\n",
                "    loader = DirectoryLoader(\n",
                "        f\"{documents_path}/{subject}\",      # Directory where source PDF files are stored\n",
                "        glob = \"*.pdf\",                          # Pattern of files to load\n",
                "        loader_cls = PyMuPDFLoader,              # PDF loading class\n",
                "    )\n",
                "    \n",
                "    # Loads documents from the directory\n",
                "    documents = loader.load()\n",
                "    \n",
                "    # Checks if there are loaded documents, otherwise ends the function\n",
                "    if not documents:\n",
                "        print(\"No documents found.\")\n",
                "        return  \n",
                "    \n",
                "    # Defines a text splitter to segment documents into smaller parts\n",
                "    text_splitter = RecursiveCharacterTextSplitter(\n",
                "        chunk_size = 512,   # Defines the maximum size of each chunk\n",
                "        chunk_overlap = 256  # Defines the overlap between chunks to maintain context\n",
                "    )\n",
                "    \n",
                "    # Divides documents into smaller chunks\n",
                "    chunks = text_splitter.split_documents(documents)\n",
                "    \n",
                "    # Name of the embeddings model used\n",
                "    # https://huggingface.co/BAAI/bge-base-en\n",
                "    model_name = emb_model_name\n",
                "    \n",
                "    # Parameters for embedding generation\n",
                "    # Defines the normalization of embeddings for similarity calculation\n",
                "    encode_kwargs = {'normalize_embeddings': True}  \n",
                "    \n",
                "    # Instantiates the embeddings model\n",
                "    embedding_model = HuggingFaceEmbeddings(\n",
                "        model_name = model_name,           # Chosen model\n",
                "        model_kwargs = {'device': 'cpu'},  # Defines execution on CPU\n",
                "        encode_kwargs = encode_kwargs      # Embeddings configuration\n",
                "    )\n",
                "\n",
                "    # Variable to store vector databases\n",
                "    vectordb = None\n",
                "    \n",
                "    # Creation of the vector database from processed documents\n",
                "    vectordb = Chroma.from_documents(\n",
                "        chunks,                                                # Chunks generated from documents\n",
                "        embedding_model,                                       # Embeddings model used\n",
                "        persist_directory = f\"{vectordb_path}/{subject}\"       # Directory where the vector database will be stored\n",
                "    )\n",
                "    \n",
                "    # Message informing that the vector database was created successfully\n",
                "    print(f\"\\nRAG Vector Database for {subject} Created Successfully.\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb128024",
            "metadata": {},
            "outputs": [],
            "source": [
                "create_vector_db(\"amd\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4eb0700",
            "metadata": {},
            "outputs": [],
            "source": [
                "create_vector_db(\"nvidia\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "81d24515",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Generating Embeddings. Please wait...\n",
                        "\n",
                        "RAG Vector Database for intel Created Successfully.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "create_vector_db(\"intel\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
